\documentclass[11pt,a4paper]{article}
\usepackage[T1]{fontenc}
% Packages
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{enumitem}

% Theorem Environments
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

% Listings Configuration
\lstset{
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{green!60!black},
    showstringspaces=false,
    breaklines=true,
    frame=single,
    captionpos=b,
}

% Document Information
\title{Resurse examen SD}
\author{Seria 15}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Sortări}
Algoritmii de sortare pot fi clasificați după complexitate, spațiu, stabilitate și dacă se bazează pe comparații:

\subsection{Clasificare}
\begin{itemize}
  \item \textbf{Elementari:} Insertion, Selection, Bubble
  \item \textbf{Divide et Impera:} Merge Sort, Quick Sort
  \item \textbf{Heap-based:} Heap Sort
  \item \textbf{Non-comparative:} Counting Sort, Radix Sort, Bucket Sort
\end{itemize}

\subsection{Stabilitate}
Un algoritm de sortare este \emph{stabil} dacă menține ordinea relativă a elementelor egale. Acest lucru este important când sortăm obiecte cu multiple chei.

\subsection{Tabel de complexități}
\begin{table}[h]
  \centering
  \begin{tabular}{l c c c c}
    \toprule
    \textbf{Algorithm}
      & \multicolumn{3}{c}{\textbf{Time Complexity}}
      & \textbf{Space (worst)} \\
    \cmidrule(lr){2-4}
      & \textbf{Best} & \textbf{Average} & \textbf{Worst} & \\
    \midrule
    Quicksort     & $\Omega(n\log n)$ & $\Theta(n\log n)$ & $O(n^2)$      & $O(\log n)$     \\
    Mergesort     & $\Omega(n\log n)$ & $\Theta(n\log n)$ & $O(n\log n)$  & $O(n)$          \\
    Timsort       & $\Omega(n)$       & $\Theta(n\log n)$ & $O(n\log n)$  & $O(n)$          \\
    Heapsort      & $\Omega(n\log n)$ & $\Theta(n\log n)$ & $O(n\log n)$  & $O(1)$          \\
    Bubble Sort   & $\Omega(n)$       & $\Theta(n^2)$     & $O(n^2)$      & $O(1)$          \\
    Insertion Sort& $\Omega(n)$       & $\Theta(n^2)$     & $O(n^2)$      & $O(1)$          \\
    Selection Sort& $\Omega(n^2)$     & $\Theta(n^2)$     & $O(n^2)$      & $O(1)$          \\
    Tree Sort     & $\Omega(n\log n)$ & $\Theta(n\log n)$ & $O(n^2)$      & $O(n)$          \\
    Shell Sort    & $\Omega(n\log n)$ & $\Theta\bigl(n(\log n)^2\bigr)$ & $O\bigl((n\log n)^2\bigr)$ & $O(1)$ \\
    Bucket Sort   & $\Omega(n + k)$   & $\Theta(n + k)$   & $O(n^2)$      & $O(n + k)$      \\
    Radix Sort    & $\Omega(n\,k)$    & $\Theta(n\,k)$    & $O(n\,k)$     & $O(n + k)$      \\
    Counting Sort & $\Omega(n + k)$   & $\Theta(n + k)$   & $O(n + k)$    & $O(n + k)$      \\
    Cubesort      & $\Omega(n)$       & $\Theta(n\log n)$ & $O(n\log n)$  & $O(n)$          \\
    \bottomrule
  \end{tabular}
  \caption{Array Sorting Algorithms: time and space complexities}
  \label{tab:sorting}
\end{table}


\subsection{Informații generale}
\begin{itemize}
  \item Sortările prin comparație au limită inferioară $\Omega(n\log n)$.
  \item Algoritmii non-comparativi (Counting, Radix) pot ajunge la $O(n)$ în condiții favorabile.
  \item Alegerea pivotului în Quick Sort influențează performanța:
  \begin{itemize}
    \item pivot ales random
    \item mediana din 3/5/7
    \item mediana medianelor
  \end{itemize}
  \item Pentru vectori mici, sortarea cu algoritmi $O(n^2)$ poate fi mai eficientă decât în $O(n\log n)$ (constanta poate fi mare).
\end{itemize}

\subsection{Counting sort}
Se creează un vector de frecvență cu valorile pe care trebuie să le sortăm. Valorile din vector sunt numărate, iar vectorul este reconstruit în ordine
sortată prin parcurgerea vectorului de frecvență.\\

\noindent
Se aplică când elementele sunt numere întregi într‐un interval \([0, k]\), (până la $10^6$)

\subsection{Bucket sort}
Se creează $k$ buckets și fiecare element $x$ din vectorul de intrare este distribuit în găleata indexată de o funcție de mapare (de ex.\ $\lfloor k\cdot\frac{x-a}{b-a}\rfloor$ pentru valori în $[a,b]$). Fiecare găleată este sortată intern (adesea prin Insertion Sort), apoi se concatenează conținutul găleților pentru a obține vectorul sortat.\\

\subsection{Radix sort}
Sortarea se face pe mai multe trepte de cifre: pentru fiecare poziție de cifră (de la LSD la MSD sau invers) se aplică Counting Sort pentru a grupa elementele după valoarea cifrei curente. După procesarea tuturor cifrelor, vectorul devine complet sortat.\\

\subsection{Quicksort}
Algoritmul Quick Sort folosește o abordare divide et impera: se selectează un pivot, iar vectorul este repartizat în două subsecțiuni, una cu elemente mai mici și cealaltă cu elemente mai mari decât pivotul. Se aplică recursiv același procedeu pe cele două subsecțiuni și, ulterior, se combină rezultatele pentru a obține vectorul sortat.\\

\subsection{Mergesort}
Merge Sort divide recursiv vectorul în jumătăți până se obțin secvențe cu un singur element (sau 2, depinde de implementare). Apoi, aceste secvențe sunt interclasate (merge) după ce au fost sortate, fiind combinate treptat pentru a forma vectorul sortat final.\\

\section{Complexități}

În studiul algoritmilor, folosim trei noțiuni fundamentale pentru a măsura creşterea funcţiei de timp \(T(n)\) în raport cu dimensiunea de intrare \(n\):

\begin{itemize}
  \item \(\mathbf{O}\) (Big-O): reprezintă o limită superioară asimptotică.
    \[
      T(n) = O(f(n)) \iff \exists\, c>0,\; n_0:\;\forall n\ge n_0,\; T(n)\le c\,f(n).
    \]
  \item \(\boldsymbol{\Omega}\) (Big-Omega): reprezintă o limită inferioară asimptotică.
    \[
      T(n) = \Omega(f(n)) \iff \exists\, c>0,\; n_0:\;\forall n\ge n_0,\; T(n)\ge c\,f(n).
    \]
  \item \(\boldsymbol{\Theta}\) (Big-Theta): când există simultan limite superioară și inferioară de același ordin.
    \[
      T(n) = \Theta(f(n)) \iff T(n) = O(f(n)) \;\wedge\; T(n) = \Omega(f(n)).
    \]
\end{itemize}

\noindent
Astfel, \(\Theta(f(n))\) indică creşterea „exactă” (în sens asimptotic), iar $O$ şi $\Omega$ doar conturul superior, respectiv inferior.

% \section{Hash-uri și Tabele de Dispersie}
% Secțiune complexă și completă în LaTeX pentru cursurile de Structuri de Date
\section{Hash-uri și Tabele de Dispersie}
\label{sec:hashuri}

\subsection{Definiții și noțiuni introductive}
\begin{definition}[Funcție de hash]
O \emph{funcție de hash} este o funcție matematică
$$h: \mathcal{U} \to \{0,1,\dots,m-1\},$$
care transformă orice element din universul de chei $\mathcal{U}$ într-o valoare de dimensiune fixă. Rezultatul $h(x)$ se numește \emph{cod hash} al lui $x$. Funcția trebuie să fie eficient de calculat și să distribuie uniform cheile.
\end{definition}

\begin{itemize}
  \item \textbf{Hash prin diviziune:} $h(x) = x \bmod p$, unde $p$ este un număr prim apropiat de $m$.
  \item \textbf{Hash prin multiplicare:} Hash-ul prin multiplicare standard folosește formula
\[
  h_a(K) = \left\lfloor \frac{(aK \bmod W)}{W/M} \right\rfloor,
\]
care produce o valoare în \(\{0,\dots,M-1\}\). Parametrul \(a\) se alege coprim cu \(W\) și cu o reprezentare binară „aleatorie” a biților. În cazul special când \(W = 2^w\) și \(M = 2^m\), formula devine
\[
  h_a(K) = \left\lfloor \frac{(aK \bmod 2^w)}{2^{\,w-m}} \right\rfloor,
\]
  \item \textbf{Proprietate dorită:}\hspace{1em} ipoteza dispersiei uniforme simple, adică pentru orice chei distincte $x,y$ avem
  $$\Pr[h(x)=h(y)] = \frac{1}{m}.$$
\end{itemize}

\subsection{Tabelă cu adresare directă}
\label{subsec:adresare-directa}
Pentru $N$ chei dintr-un univers mic $\{1,\dots,N\}$, putem implementa direct o tăblă de dispersie printr-un vector binar:
\[
  A[1\dots N], \quad A[i] = \begin{cases}1 & \text{dacă }i\text{ este prezent,} \\ 0 & \text{altfel.}\end{cases}
\]
Operații:
\begin{itemize}
  \item \texttt{insert(x)}: $A[x] \leftarrow 1$, cost $O(1)$.
  \item \texttt{find(x)}: returnează $A[x]$, cost $O(1)$.
  \item \texttt{delete(x)}: $A[x] \leftarrow 0$, cost $O(1)$.
\end{itemize}

\subsection{Tabele de dispersie cu coliziuni}
\label{subsec:coliziuni}
Pentru universuri mai mari sau chei arbitrare, folosim o funcție de hash $h$ și rezolvăm coliziunile prin:
\begin{enumerate}
  \item \textbf{Listă înlănțuită (chaining).}
  \item \textbf{Adresare deschisă (open addressing).}
\end{enumerate}

\subsubsection{Chaining}
Fie $T[0\dots m-1]$ un vector de liste înlănțuite. La inserare, adăugăm $x$ în lista $T[h(x)]$. Căutarea parcurge lista, cost amortizat $O(1 + \alpha)$, unde $\alpha = n/m$.

\subsubsection{Adresare deschisă}
Coliziunile se rezolvă prin sondaj:\\
\begin{description}
  \item[Lineară:] $h(x,i) = (h_0(x) + i) \bmod m$.
  \item[Dublu hashing:] $h(x,i) = (h_1(x) + i\cdot h_2(x)) \bmod m$.
\end{description}
În cel mai rău caz, operațiile costă $O(m)$, dar dacă $\alpha < 1$ și funcțiile sunt bine alese, costul mediu este $O(1)$.

\subsection{Dispersie universală}
\label{subsec:dispersie-universala}
\begin{definition}[Familie universală]
O familie de funcții de dispersie $\mathcal{H}$ este \emph{universală} dacă pentru orice $x\neq y$ din $\mathcal{U}$,
$$\bigl|\{h\in\mathcal{H} : h(x)=h(y)\}\bigr| = \frac{|\mathcal{H}|}{m}.$$
\end{definition}
Consecință: pentru $n\le m$ și $h$ ales aleator din $\mathcal{H}$, numărul mediu de coliziuni pentru o cheie fixă este mai mic decât 1.

\subsection{Algoritmul Rabin--Karp pentru pattern matching}
Pentru a găsi un șablon (pattern) $P$ de lungime $m$ într-un text $T$ de lungime $n$, folosim un hash pentru substring.
\begin{itemize}
  \item Alegem o bază $b$ (de obicei dimensiunea alfabetului) și un număr $M$.
  \item Calculăm hash-ul pattern-ului (substringu-ului)
  $$h_P = \sum_{i=0}^{m-1} P[i]\,b^{m-1-i} \bmod M.$$
  \item Rolling hash-ul fiecărei ferestre de text de lungime $m$:
  $$H_{0} = \sum_{i=0}^{m-1} T[i]\,b^{m-1-i} \bmod M,$$
  $$H_{i+1} = \bigl(b\,(H_i - T[i]\,b^{m-1}) + T[i+m]\bigr) \bmod M.$$
\end{itemize}
Dacă $H_i = h_P$, facem o verificare explicită $T[i..i+m-1]=P$ pentru a evita \emph{false positives}. Complexitatea totală este $O(n+m)$ în medie.


\subsection{Complexități}
\begin{table}[H]
\centering
\begin{tabular}{l|ccc}
\textbf{Structură} & \textbf{Insert} & \textbf{Find} & \textbf{Delete} \\
\hline
Directă & $O(1)$ & $O(1)$ & $O(1)$ \\
Chaining & $O(1+\alpha)$ & $O(1+\alpha)$ & $O(1+\alpha)$ \\
Open addressing & $O(1/(1-\alpha))$ & $O(1/(1-\alpha))$ & $O(1/(1-\alpha))$ \\
\end{tabular}
\caption{Complexități medii pentru tabele de dispersie}
\label{tbl:complexitati}
\end{table}



\end{document}
